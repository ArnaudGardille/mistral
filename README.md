# Mistral

> *Mistral*: A strong and cool northwesterly wind that builds as it moves, bringing good health and clear skies.

A framework for fast and efficient large-scale language model training, built with Hugging Face :hugs:. Includes tools
and helpful scripts for incorporating new pre-training datasets, various schemes for single node and distributed
training, and importantly, scripts for evaluation and measuring bias.

A Project Mercury Endeavor.

---

## Quickstart

# Installation

```bash
git clone https://github.com/stanford-mercury/mistral.git
cd mistral
conda env create -f environments/environment-gpu.yaml  # Choose CUDA Kernel based on Hardware!
conda activate mistral
```

---

## Start-Up (from Scratch)

Use these commands if you're starting a repository from scratch (this shouldn't be necessary to use this repo, but is
included for completeness). If you're just trying to run/use this code, look at the Quickstart section above.

## Contributing

Please see our [Read The Docs](https://nlp.stanford.edu/local/mistral/docs/_build/html/contributing.html) page for info on contributing.
